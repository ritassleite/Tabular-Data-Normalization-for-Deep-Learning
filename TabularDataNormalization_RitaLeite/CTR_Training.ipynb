{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6410,
     "status": "ok",
     "timestamp": 1669981470415,
     "user": {
      "displayName": "Rita Leite",
      "userId": "14494695781533120685"
     },
     "user_tz": 0
    },
    "id": "24Qjto8r7t5Z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritas\\anaconda3\\lib\\site-packages\\pytorch_tabular\\models\\mixture_density\\mdn.py:25: UserWarning: Wandb not installed. WandbLogger will not work.\n",
      "  warnings.warn(\"Wandb not installed. WandbLogger will not work.\")\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "import scipy\n",
    "import opendatasets as od\n",
    "import math\n",
    "import torchmetrics\n",
    "import utils.lgbm as lgbm\n",
    "import importlib\n",
    "import joblib\n",
    "import category_encoders\n",
    "import matplotlib.pyplot as plt\n",
    "#Pipeline to train MLPs\n",
    "import utils.mlp as mlp\n",
    "import utils.mlp_pipeline as mlp_pipeline\n",
    "import utils.embedding_pipeline as embedding_pipeline\n",
    "from rtdl.rtdl import data as data\n",
    "import pytorch_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1669981470418,
     "user": {
      "displayName": "Rita Leite",
      "userId": "14494695781533120685"
     },
     "user_tz": 0
    },
    "id": "yF0jDCkTPUSU"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import io\n",
    "\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else:\n",
    "            return super().find_class(module, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate recall at FPR of rate\n",
    "\n",
    "def find_optimal_recall(y_true,y_pred,rate):\n",
    "    fpr,tpr,thresholds=skl.metrics.roc_curve(y_true,y_pred,drop_intermediate=False)\n",
    "    optimal_index=np.argmin(abs(fpr-rate*np.ones(len(fpr))))\n",
    "    return tpr[optimal_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1669981470420,
     "user": {
      "displayName": "Rita Leite",
      "userId": "14494695781533120685"
     },
     "user_tz": 0
    },
    "id": "1MjXEJlP7vhC",
    "outputId": "fe7d4ad3-074b-48e3-95ab-cedb3852ba68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21882,
     "status": "ok",
     "timestamp": 1669981492289,
     "user": {
      "displayName": "Rita Leite",
      "userId": "14494695781533120685"
     },
     "user_tz": 0
    },
    "id": "d-BEFwm-9PMw",
    "outputId": "e54eb096-73da-43ff-8e97-f813dead5d7e"
   },
   "outputs": [],
   "source": [
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3311,
     "status": "ok",
     "timestamp": 1669982639929,
     "user": {
      "displayName": "Rita Leite",
      "userId": "14494695781533120685"
     },
     "user_tz": 0
    },
    "id": "06oWTk7Q78Li",
    "outputId": "1c636f9d-89b9-45f0-8db8-39327d4ad2bf"
   },
   "outputs": [],
   "source": [
    "#Kaggle api key: 9c2fc93aaaf8815d9fa8f2ceeeb57b6b\n",
    "#od.download(\"https://www.kaggle.com/c/avazu-ctr-prediction/\")\n",
    "\n",
    "ctr_data=pd.read_csv(\"./avazu-ctr-prediction/train.gz\",nrows=1000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_pipeline=importlib.reload(embedding_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1276,
     "status": "ok",
     "timestamp": 1669982641198,
     "user": {
      "displayName": "Rita Leite",
      "userId": "14494695781533120685"
     },
     "user_tz": 0
    },
    "id": "RcAd6f9j8KLl",
    "outputId": "58f2cc4e-91ab-4189-bd82-cbc1f963428e"
   },
   "outputs": [],
   "source": [
    "X=ctr_data.loc[:,'C1':'C21']\n",
    "Y=ctr_data.click\n",
    "\n",
    "del ctr_data\n",
    "\n",
    "    \n",
    "training_range=range(0,math.floor(len(Y)*0.6))\n",
    "validation_range=range(math.floor(len(Y)*0.6),math.floor(len(Y)*0.8))\n",
    "testing_range=range(math.floor(len(Y)*0.8),math.floor(len(Y)*1))\n",
    "\n",
    "#Establish continuous and categorical features\n",
    "cat_cols=X.columns\n",
    "cont_cols=X.columns.difference(cat_cols)\n",
    "\n",
    "\n",
    "xtrain=X.loc[training_range]\n",
    "ytrain=Y.loc[training_range]\n",
    "xtest=X.loc[testing_range]\n",
    "ytest=Y.loc[testing_range]\n",
    "xval=X.loc[validation_range]\n",
    "yval=Y.loc[validation_range]\n",
    "\n",
    "x_train,x_test,x_val=embedding_pipeline.aggregate_low_card(xtrain,xtest,xval,cat_cols)\n",
    "\n",
    "del X\n",
    "del Y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1669981756395,
     "user": {
      "displayName": "Rita Leite",
      "userId": "14494695781533120685"
     },
     "user_tz": 0
    },
    "id": "Hig88ksgqzWc"
   },
   "outputs": [],
   "source": [
    "cat_cols=xtrain.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYiLlNpq5hi8"
   },
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=['C1', 'banner_pos', 'site_id', 'site_domain', 'site_category', 'app_id',\n",
    "       'app_domain', 'app_category', 'device_id', 'device_ip', 'device_model',\n",
    "       'device_type', 'device_conn_type', 'C14', 'C15', 'C16', 'C17', 'C18',\n",
    "       'C19', 'C20', 'C21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lgbm\n",
    "aux=importlib.reload(lgbm)\n",
    "param_list=lgbm.lgbm_param_sampler(20,7,'cpu')\n",
    "print(len(param_list))\n",
    "print(param_list[0])\n",
    "i=0\n",
    "for col in xtrain.select_dtypes(object).columns:\n",
    "    print(col)\n",
    "    le=skl.preprocessing.LabelEncoder()\n",
    "    xtrain[col]=le.fit_transform(xtrain[col])\n",
    "    xtest[col] = xtest[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
    "    xval[col] = xval[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
    "    le.classes_ = np.append(le.classes_, '<unknown>')\n",
    "    xtest[col]=le.transform(xtest[col])\n",
    "    xval[col]=le.transform(xval[col])\n",
    "for col in xtrain.select_dtypes(float).columns:\n",
    "    xtrain[col]=xtrain[col].fillna(np.average(xtrain[col]))\n",
    "    xtest[col]=xtest[col].fillna(np.average(xtest[col]))\n",
    "    xval[col]=xval[col].fillna(np.average(xtest[col]))\n",
    "\n",
    "xtrain=xtrain.fillna(-1)\n",
    "xtest=xtest.fillna(-1)\n",
    "xval=xval.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 940380,
     "status": "ok",
     "timestamp": 1669984326804,
     "user": {
      "displayName": "Rita Leite",
      "userId": "14494695781533120685"
     },
     "user_tz": 0
    },
    "id": "ENo3TwbF9M1z",
    "outputId": "5990e865-66e6-4cf4-af4b-7dba72eb2b1b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_auc=-10\n",
    "for params in param_list:\n",
    "    model = lgb.LGBMClassifier(n_jobs=10, **params)  # Instantiate LGBM Model.\n",
    "        \n",
    "    # Fit model to training data.\n",
    "    model.fit(xtrain, ytrain,categorical_feature=cat_cols,eval_set=[(xval,yval)],early_stopping_rounds=5,eval_metric='loss',verbose=False)\n",
    "    # Obtain predictions in test data.\n",
    "    predictions = model.predict_proba(x_val)[:, 1]\n",
    "    auc=skl.metrics.roc_auc_score(yval,predictions)\n",
    "    if auc>max_auc:\n",
    "        best_lgbm=model\n",
    "        max_auc=auc\n",
    "joblib.dump(best_lgbm,'LGBM_CTR/best_lgbm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list=lgbm.lgbm_param_sampler(20,7,'cpu')\n",
    "\n",
    "target_encoder=category_encoders.target_encoder.TargetEncoder(cols=cat_cols,handle_unknown='value',handle_missing='value')\n",
    "catboost_encoder=category_encoders.cat_boost.CatBoostEncoder(cols=cat_cols,handle_unknown='value',handle_missing='value',drop_invariant=False,return_df=True,sigma=0)\n",
    "count_encoder=category_encoders.count.CountEncoder(cols=cat_cols,verbose=0,handle_unknown='value',handle_missing='value',normalize=True,min_group_size=0.005,min_group_name='Leftover',combine_min_nan_groups=False)\n",
    "enc=[catboost_encoder,count_encoder,target_encoder]\n",
    "j=0\n",
    "for encoding in ['cat','count','target']:\n",
    "    encoder=enc[j]\n",
    "    xtrain_aux=encoder.fit_transform(xtrain,ytrain)\n",
    "    xval_aux=encoder.transform(xval)\n",
    "    i=0\n",
    "    for params in param_list:\n",
    "        model = lgb.LGBMClassifier(n_jobs=10, **params)  # Instantiate LGBM Model.\n",
    "        \n",
    "        # Fit model to training data.\n",
    "        model.fit(xtrain_aux, ytrain,eval_set=[(xval_aux,yval)],early_stopping_rounds=5,eval_metric='loss',verbose=False)\n",
    "        joblib.dump(model,'LGBM_CTR/lgbm_{}{}'.format(encoding,i))\n",
    "        i=i+1\n",
    "    del xtrain_aux\n",
    "    del xval_aux\n",
    "    gc.collect()\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PxM0Nk2nqcWg"
   },
   "outputs": [],
   "source": [
    "best_lgbm=joblib.load('LGBM_CTR/best_lgbm.pkl')\n",
    "predict= best_lgbm.predict_proba(xtest)[:, 1]\n",
    "\n",
    "auc_lgb=skl.metrics.roc_auc_score(ytest,predict)\n",
    "roc_lgb=skl.metrics.roc_curve(ytest,predict,drop_intermediate=False)\n",
    "recall_lgb=find_optimal_recall(ytest,predict,0.05)\n",
    "\n",
    "print(round(auc_lgb,5),'&',round(recall_lgb,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritas\\anaconda3\\lib\\site-packages\\category_encoders\\target_encoder.py:122: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "C:\\Users\\ritas\\anaconda3\\lib\\site-packages\\category_encoders\\target_encoder.py:127: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM with  cat  encoding:  0.75068 0.2126\n",
      "LightGBM with  count  encoding:  0.7112 0.19341\n",
      "LightGBM with  target  encoding:  0.73231 0.20192\n"
     ]
    }
   ],
   "source": [
    "target_encoder=category_encoders.target_encoder.TargetEncoder(cols=cat_cols,handle_unknown='value',handle_missing='value')\n",
    "catboost_encoder=category_encoders.cat_boost.CatBoostEncoder(cols=cat_cols,handle_unknown='value',handle_missing='value',drop_invariant=False,return_df=True,sigma=0)\n",
    "count_encoder=category_encoders.count.CountEncoder(cols=cat_cols,verbose=0,handle_unknown='value',handle_missing='value',normalize=True,min_group_size=0.005,min_group_name='Leftover',combine_min_nan_groups=False)\n",
    "enc=[catboost_encoder,count_encoder,target_encoder]\n",
    "j=0\n",
    "for encoding in ['cat','count','target']:\n",
    "    encoder=enc[j]\n",
    "    encoder=encoder.fit(xtrain,ytrain)\n",
    "    xval_aux=encoder.transform(xval)\n",
    "    xtest_aux=encoder.transform(xtest)\n",
    "    max_auc=0\n",
    "    for i in range(0,20):\n",
    "        model=joblib.load(\"lgbm_3/lgbm_{}{}\".format(encoding,i))\n",
    "        predict=model.predict_proba(xval_aux)[:,1]\n",
    "        auc=skl.metrics.roc_auc_score(yval,predict)\n",
    "        if auc>max_auc:\n",
    "            max_auc=auc\n",
    "            best_model=model\n",
    "    predict_test=best_model.predict_proba(xtest_aux)[:,1]\n",
    "    auc=skl.metrics.roc_auc_score(ytest,predict_test)\n",
    "    recall=find_optimal_recall(ytest,predict_test,0.05)\n",
    "    print('LightGBM with ',encoding,' encoding: ',round(auc,5),round(recall,5))\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBPAlLBo5nRa"
   },
   "source": [
    "# Categorical Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8578,
     "status": "ok",
     "timestamp": 1669902547061,
     "user": {
      "displayName": "Rita Leite",
      "userId": "14494695781533120685"
     },
     "user_tz": 0
    },
    "id": "hgXJY7QY5rTi",
    "outputId": "6b874cbe-40a8-455e-d5c0-667179f627eb"
   },
   "outputs": [],
   "source": [
    "cat_cols=xtrain.columns\n",
    "cont_cols=xtrain.columns.difference(cat_cols)\n",
    "\n",
    "target_encoder=category_encoders.target_encoder.TargetEncoder(cols=cat_cols,handle_unknown='value',handle_missing='value')\n",
    "xtrain_encoded=target_encoder.fit_transform(xtrain,ytrain)\n",
    "xval_encoded=target_encoder.transform(xval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEyq4biABGJZ"
   },
   "source": [
    "# CatBoost Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "catboost_encoder=category_encoders.cat_boost.CatBoostEncoder(cols=cat_cols,handle_unknown='value',handle_missing='value',drop_invariant=False,return_df=True,sigma=0)\n",
    "xtrain_cat=catboost_encoder.fit_transform(xtrain,ytrain)\n",
    "xval_cat=catboost_encoder.transform(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define number of trials in Random search.\n",
    "n_trials=20\n",
    "\n",
    "# Variable to store the results.\n",
    "runs = {}\n",
    "param_list=mlp.mlp_param_sampler(n_trials, len(xtrain.columns),7,device)\n",
    "\n",
    "\n",
    "\n",
    "normalization=['None','Zscore','MinMax','Median']\n",
    "\n",
    "for norm in normalization:\n",
    "    xtrain_aux=mlp_pipeline.normalization_transform(xtrain_cat,norm,xtrain.columns)\n",
    "    xval_aux=mlp_pipeline.normalization_transform(xval_cat,norm,xtrain.columns)\n",
    "    i=0\n",
    "\n",
    "    for params in param_list[i:]:\n",
    "        # Fit pipeline\n",
    "    \n",
    "        print('iteration: ',i,'Normalization:',norm)\n",
    "        \n",
    "        model=mlp_pipeline.pipeline(device,xtrain_aux,xval_aux,ytrain,ytest,params,'None',cont_cols)\n",
    "\n",
    "        #Save the model\n",
    "        joblib.dump(model,'CTR_mlp/mlp_cat{}{}.pkl'.format(norm,i))\n",
    "\n",
    "        i=i+1\n",
    "    del xval_aux\n",
    "    del xtrain_aux\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder=category_encoders.target_encoder.TargetEncoder(cols=cat_cols,handle_unknown='value',handle_missing='value')\n",
    "xtrain_aux=target_encoder.fit_transform(xtrain,ytrain)\n",
    "xval_aux=target_encoder.transform(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlp\n",
    "import mlp_pipeline\n",
    "mlp_pipeline=importlib.reload(mlp_pipeline)\n",
    "\n",
    "# Define number of trials in Random search.\n",
    "n_trials=20\n",
    "\n",
    "\n",
    "# Variable to store the results.\n",
    "runs = {}\n",
    "param_list=mlp.mlp_param_sampler(n_trials, len(xtrain.columns),7,device)\n",
    "\n",
    "times=np.zeros(20)\n",
    "\n",
    "normalization=['None','Zscore','MinMax','Median']\n",
    "\n",
    "for norm in normalization:\n",
    "    xtrain_aux=mlp_pipeline.normalization_transform(xtrain_aux,norm,xtrain.columns)\n",
    "    xval_aux=mlp_pipeline.normalization_transform(xval_aux,norm,xtrain.columns)\n",
    "    i=0\n",
    "\n",
    "    for params in param_list[i:]:\n",
    "        # Fit pipeline\n",
    "    \n",
    "        print('iteration: ',i,'Normalization:',norm)\n",
    "        model=mlp_pipeline.pipeline(device,xtrain_aux,xval_aux,ytrain,ytest,params,'None',cont_cols)\n",
    "\n",
    "        #Save the model\n",
    "        joblib.dump(model,'CTR_mlp/mlp_final_target{}{}.pkl'.format(norm,i))\n",
    "    \n",
    "        i=i+1\n",
    "    del xval_aux\n",
    "    del xtrain_aux\n",
    "    gc.collect()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_encoder=category_encoders.count.CountEncoder(cols=cat_cols,verbose=0,handle_unknown='value',handle_missing='value',normalize=True,min_group_size=0.005,min_group_name='Leftover',combine_min_nan_groups=False)\n",
    "\n",
    "xtrain_aux=count_encoder.fit_transform(xtrain,ytrain)\n",
    "xval_aux=count_encoder.transform(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define number of trials in Random search.\n",
    "n_trials=20\n",
    "\n",
    "param_list=mlp.mlp_param_sampler(n_trials, len(xtrain.columns),7,device)\n",
    "\n",
    "\n",
    "\n",
    "normalization=['None','Zscore','MinMax','Median']\n",
    "\n",
    "for norm in normalization:\n",
    "    xtrain_aux_temp=mlp_pipeline.normalization_transform(xtrain_aux,norm,xtrain.columns)\n",
    "    xval_aux_temp=mlp_pipeline.normalization_transform(xval_aux,norm,xtrain.columns)\n",
    "    i=0\n",
    "    times=np.zeros(20)\n",
    "    for params in param_list[i:]:\n",
    "        # Fit pipeline\n",
    "    \n",
    "        print('iteration: ',i,'Normalization:',norm)\n",
    "        model=mlp_pipeline.pipeline(device,xtrain_aux_temp,xval_aux_temp,ytrain,ytest,params,'None',cont_cols)\n",
    "        #Save the model\n",
    "        joblib.dump(model,'CTR_MLP/mlp_count{}{}.pkl'.format(norm,i))\n",
    "        i=i+1\n",
    "    del xval_aux_temp\n",
    "    del xtrain_aux_temp\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(14,20):\n",
    "    if i==3 or i==12 or i==5 or i==13:\n",
    "        print(i,' none')\n",
    "    elif i>=4:\n",
    "        file=open('tabtransformer_CTR/tabtransformerCTR_{}'.format(i),'rb')\n",
    "        model=joblib.load(file)\n",
    "        predict=model.predict(xval)['1_probability']\n",
    "    else:\n",
    "        model=joblib.load('tabtransformer_CTR/tabtransformerCTR_{}.pkl'.format(i))\n",
    "        predict=model.predict(xval)['1_probability']\n",
    "    auc=skl.metrics.roc_auc_score(yval,predict)\n",
    "    recall=find_optimal_recall(yval,predict,0.05)\n",
    "    \n",
    "    if auc>max_auc:\n",
    "        max_auc=auc\n",
    "        best_model=model\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_test=best_model.predict(xtest)['1_probability']\n",
    "auc_test=skl.metrics.roc_auc_score(ytest,predict_test)\n",
    "recall_test=find_optimal_recall(ytest,predict_test,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, let us look at the effects of normalization seperatly\n",
    "auc_scores=np.zeros([4,4,20])\n",
    "recall_scores=np.zeros([4,4,20])\n",
    "k=0\n",
    "enc=[catboost_encoder,count_encoder,target_encoder]\n",
    "for encoding in ['cat','count','target']:\n",
    "    j=0\n",
    "    encoder=enc[j]\n",
    "    xval_aux=encoder.transform(xval)\n",
    "    for normalization in ['None','Zscore','MinMax','Median']:\n",
    "        \n",
    "        X_val_normalized=mlp_pipeline.normalization_transform(xval_aux,normalization,xval_aux.columns).float()\n",
    "            \n",
    "        for i in range(0,20):\n",
    "            if encoding=='target' and (normalization=='MinMax' or normalization=='Median'):\n",
    "                link=\"mlp_3/mlp_final_{}{}{}.pkl\".format(encoding,normalization,i)\n",
    "            else:\n",
    "                link=\"mlp_3/mlp_{}{}{}.pkl\".format(encoding,normalization,i)\n",
    "            file = open(link,'rb')\n",
    "            model = CPU_Unpickler(file).load()\n",
    "            model.eval()\n",
    "            predict = model(X_val_normalized)\n",
    "            auc=skl.metrics.roc_auc_score(yval,predict.detach().numpy())\n",
    "            roc=skl.metrics.roc_curve(yval,predict.detach().numpy(),drop_intermediate=False)\n",
    "            recall=find_optimal_recall(roc[0],roc[1],roc[2],0.05)\n",
    "            auc_scores[k][j][i]=auc\n",
    "            recall_scores[k][j][i]=recall\n",
    "        del X_val_normalized\n",
    "        gc.collect\n",
    "        j=j+1\n",
    "    k=k+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat None --- 0.73987  &  0.20916\n",
      "cat Zscore --- 0.74299  &  0.20542\n",
      "cat MinMax --- 0.73848  &  0.20419\n",
      "cat Median --- 0.73298  &  0.20328\n",
      "count None --- 0.66527  &  0.17812\n",
      "count Zscore --- 0.66787  &  0.17171\n",
      "count MinMax --- 0.67921  &  0.18413\n",
      "count Median --- 0.61501  &  7e-05\n",
      "target None --- 0.72991  &  0.19848\n",
      "target Zscore --- 0.71782  &  0.22281\n",
      "target MinMax --- 0.73869  &  0.20562\n",
      "target Median --- 0.69828  &  0.1615\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "for encoding in ['cat','count','target']:\n",
    "\n",
    "    param_list=mlp.mlp_param_sampler(20, len(xtrain.columns),7,device)\n",
    "    xtest_aux=catboost_encoder.transform(xtest)\n",
    "    norms= ['None','Zscore','MinMax','Median']\n",
    "    \n",
    "    encoder=enc[j]\n",
    "    xtest_aux=encoder.transform(xtest)\n",
    "    best_link=np.array(np.zeros([4,4]),dtype=object)\n",
    "    for i in range(0,4):\n",
    "        X_test_normalized=mlp_pipeline.normalization_transform(xtest_aux,norms[i],xtest.columns).float()        \n",
    "        index=np.argmax(auc_scores[j][i])\n",
    "        if encoding=='target' and (norms[i]=='MinMax' or norms[i]=='Median'):\n",
    "            best_link[j][i]=\"mlp_3/mlp_final_{}{}{}.pkl\".format(encoding,norms[i],index)\n",
    "        else:\n",
    "            best_link[j][i]=\"mlp_3/mlp_{}{}{}.pkl\".format(encoding,norms[i],index)\n",
    "        file = open(best_link[j][i],'rb')\n",
    "        model = CPU_Unpickler(file).load()\n",
    "        model.eval()\n",
    "        predict = model(X_test_normalized)\n",
    "        auc=skl.metrics.roc_auc_score(ytest,predict.detach().numpy())\n",
    "        roc=skl.metrics.roc_curve(ytest,predict.detach().numpy(),drop_intermediate=False)\n",
    "        recall=find_optimal_recall(roc[0],roc[1],roc[2],0.05)\n",
    "        print(encoding,norms[i],'---',round(auc,5),\" & \",round(recall,5))\n",
    "        del X_test_normalized\n",
    "        gc.collect\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73988 & 0.21022\n"
     ]
    }
   ],
   "source": [
    "emb_auc=np.zeros(20)\n",
    "emb_recall=np.zeros(20)\n",
    "\n",
    "x_train,x_test,x_val=embedding_pipeline.aggregate_low_card_BAF(xtrain,xtest,xval,cat_cols)\n",
    "\n",
    "xval_aux_cont=torch.tensor([])\n",
    "\n",
    "xval_aux_cat=mlp_pipeline.normalization_transform(x_val,'None',[])\n",
    "max_auc=0\n",
    "for i in range(0,20):\n",
    "    link='CTR_mlp/mlp_3_emb/mlp_simplevariational{}.pkl'.format(i)\n",
    "    file = open(link,'rb')\n",
    "    model = CPU_Unpickler(file).load()\n",
    "    model.eval()\n",
    "    predict = model(xval_aux_cont.float(),xval_aux_cat.long()).detach().numpy()\n",
    "    auc=skl.metrics.roc_auc_score(yval,predict)\n",
    "    recall=find_optimal_recall(yval,predict,0.05)\n",
    "    emb_auc[i]=auc\n",
    "    emb_recall[i]=recall\n",
    "    if auc>max_auc:\n",
    "        max_auc=auc\n",
    "        best_model=model\n",
    "        \n",
    "xtest_aux_cont=torch.tensor([])\n",
    "xtest_aux_cat=mlp_pipeline.normalization_transform(x_test,'None',[])\n",
    "predict = model(xval_aux_cont.float(),xval_aux_cat.long()).detach().numpy()\n",
    "auc=skl.metrics.roc_auc_score(yval,predict)\n",
    "recall=find_optimal_recall(yval,predict,0.05)\n",
    "print(round(auc,5),'&',round(recall,5))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPAN7UdPCHN56e9EpSIPEoz",
   "collapsed_sections": [
    "JYiLlNpq5hi8",
    "lBPAlLBo5nRa"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
