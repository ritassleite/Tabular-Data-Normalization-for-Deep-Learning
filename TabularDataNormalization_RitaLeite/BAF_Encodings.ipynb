{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "Hfwzsu8Hn_fh",
        "outputId": "20fbcbd9-4eb0-44b7-c021-de830713c31c"
      },
      "outputs": [],
      "source": [
        "\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn as skl\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import scipy\n",
        "import opendatasets as od\n",
        "import math\n",
        "import torchmetrics\n",
        "import importlib\n",
        "import joblib\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders\n",
        "import pickle\n",
        "import io\n",
        "import yaml              \n",
        "\n",
        "from matplotlib import pyplot as plt            \n",
        "from sklearn.preprocessing import LabelEncoder  \n",
        "from sklearn import metrics                     \n",
        "\n",
        "import utils.mlp as mlp\n",
        "import utils.mlp_pipeline as mlp_pipeline\n",
        "import utils.embedding_pipeline as embedding_pipeine\n",
        "\n",
        "from bank_account_fraud.notebooks.random_search import RandomValueTrial, suggest_callable_hyperparams  # from repository https://github.com/feedzai/bank-account-fraud.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcC1B0Uk6lp5"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNKh5QAYoAHz"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class CPU_Unpickler(pickle.Unpickler):\n",
        "    def find_class(self, module, name):\n",
        "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
        "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
        "        else:\n",
        "            return super().find_class(module, name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M24dfxIUoFYG",
        "outputId": "826884a3-d264-498e-a1cb-6034e7aac151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"Using {device} device\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELUgMJ7toIcM",
        "outputId": "366bb555-01e4-4d1f-dc76-c3496906dc0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: ritaleite\n",
            "Your Kaggle Key: ··········\n",
            "Downloading bank-account-fraud-dataset-neurips-2022.zip to ./bank-account-fraud-dataset-neurips-2022\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 546M/546M [00:28<00:00, 20.3MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "od.download(\"https://www.kaggle.com/datasets/sgpjesus/bank-account-fraud-dataset-neurips-2022?select=Base.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIgmNosYoLPH"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "extension = \"csv\"  # or \"parquet\", depending on the downloaded file\n",
        "data_paths = glob.glob(f\"</path/to/datasets/>*.{extension}\")\n",
        "\n",
        "def read_dataset(path, ext=extension):\n",
        "    if ext == \"csv\":\n",
        "        return pd.read_csv(path, index_col=0)\n",
        "    elif ext == \"parquet\":\n",
        "        return pd.read_parquet(path)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid extension: '{ext}'.\")\n",
        "\n",
        "def get_variant(path):\n",
        "        return path.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "dataframes = {\n",
        "    get_variant(path): read_dataset(path) for path in data_paths\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0etk8ti2oPDS"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Read hyperparameter space for the LGBM Models, expected structure is presented bellow\n",
        "with open(\"/content/gdrive/MyDrive/tab_norm_folder/bank_account_fraud/notebooks/lightgbm_hyperparameter_space.yaml\", \"r\") as file:\n",
        "    hyperparam_space = yaml.load(file, Loader=yaml.FullLoader)\n",
        "\n",
        "\n",
        "# Define path to datasets. Replace `base_path` with the appropriate value.\n",
        "base_path = \"/content/bank-account-fraud-dataset-neurips-2022/\"\n",
        "\n",
        "datasets_paths = {\n",
        "    \"Base\":    base_path + \"Base.csv\",\n",
        "}\n",
        "\n",
        "datasets = {key: pd.read_csv(path) for key, path in datasets_paths.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3h-ddffoglg",
        "outputId": "9c726768-371e-4ee7-e00d-88030b233ad1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           fraud_bool          income  name_email_similarity  \\\n",
            "count  1000000.000000  1000000.000000         1000000.000000   \n",
            "mean         0.011029        0.562696               0.493694   \n",
            "std          0.104438        0.290343               0.289125   \n",
            "min          0.000000        0.100000               0.000001   \n",
            "25%          0.000000        0.300000               0.225216   \n",
            "50%          0.000000        0.600000               0.492153   \n",
            "75%          0.000000        0.800000               0.755567   \n",
            "max          1.000000        0.900000               0.999999   \n",
            "\n",
            "       prev_address_months_count  current_address_months_count  \\\n",
            "count             1000000.000000                1000000.000000   \n",
            "mean                   16.718568                     86.587867   \n",
            "std                    44.046230                     88.406599   \n",
            "min                    -1.000000                     -1.000000   \n",
            "25%                    -1.000000                     19.000000   \n",
            "50%                    -1.000000                     52.000000   \n",
            "75%                    12.000000                    130.000000   \n",
            "max                   383.000000                    428.000000   \n",
            "\n",
            "         customer_age  days_since_request  intended_balcon_amount  \\\n",
            "count  1000000.000000        1.000000e+06          1000000.000000   \n",
            "mean        33.689080        1.025705e+00                8.661499   \n",
            "std         12.025799        5.381835e+00               20.236155   \n",
            "min         10.000000        4.036860e-09              -15.530555   \n",
            "25%         20.000000        7.193246e-03               -1.181488   \n",
            "50%         30.000000        1.517574e-02               -0.830507   \n",
            "75%         40.000000        2.633069e-02                4.984176   \n",
            "max         90.000000        7.845690e+01              112.956928   \n",
            "\n",
            "         zip_count_4w     velocity_6h  ...  phone_mobile_valid  \\\n",
            "count  1000000.000000  1000000.000000  ...      1000000.000000   \n",
            "mean      1572.692049     5665.296605  ...            0.889676   \n",
            "std       1005.374565     3009.380665  ...            0.313293   \n",
            "min          1.000000     -170.603072  ...            0.000000   \n",
            "25%        894.000000     3436.365848  ...            1.000000   \n",
            "50%       1263.000000     5319.769349  ...            1.000000   \n",
            "75%       1944.000000     7680.717827  ...            1.000000   \n",
            "max       6700.000000    16715.565404  ...            1.000000   \n",
            "\n",
            "       bank_months_count  has_other_cards  proposed_credit_limit  \\\n",
            "count     1000000.000000   1000000.000000         1000000.000000   \n",
            "mean           10.839303         0.222988             515.851010   \n",
            "std            12.116875         0.416251             487.559902   \n",
            "min            -1.000000         0.000000             190.000000   \n",
            "25%            -1.000000         0.000000             200.000000   \n",
            "50%             5.000000         0.000000             200.000000   \n",
            "75%            25.000000         0.000000             500.000000   \n",
            "max            32.000000         1.000000            2100.000000   \n",
            "\n",
            "       foreign_request  session_length_in_minutes  keep_alive_session  \\\n",
            "count   1000000.000000             1000000.000000      1000000.000000   \n",
            "mean          0.025242                   7.544940            0.576947   \n",
            "std           0.156859                   8.033106            0.494044   \n",
            "min           0.000000                  -1.000000            0.000000   \n",
            "25%           0.000000                   3.103053            0.000000   \n",
            "50%           0.000000                   5.114321            1.000000   \n",
            "75%           0.000000                   8.866131            1.000000   \n",
            "max           1.000000                  85.899143            1.000000   \n",
            "\n",
            "       device_distinct_emails_8w  device_fraud_count           month  \n",
            "count             1000000.000000           1000000.0  1000000.000000  \n",
            "mean                    1.018312                 0.0        3.288674  \n",
            "std                     0.180761                 0.0        2.209994  \n",
            "min                    -1.000000                 0.0        0.000000  \n",
            "25%                     1.000000                 0.0        1.000000  \n",
            "50%                     1.000000                 0.0        3.000000  \n",
            "75%                     1.000000                 0.0        5.000000  \n",
            "max                     2.000000                 0.0        7.000000  \n",
            "\n",
            "[8 rows x 27 columns]\n"
          ]
        }
      ],
      "source": [
        "print(datasets['Base'].describe())\n",
        "\n",
        "\n",
        "# Create the train and test sets. Shuffle data with `sample` method.\n",
        "# The split was done by month. The first 6 months as the train, the last 2 months as test.\n",
        "train_dfs = {key: df[df[\"month\"]<6].sample(frac=1, replace=False) for key, df in datasets.items()}\n",
        "val_dfs = {key: df[df[\"month\"]==6].sample(frac=1, replace=False) for key, df in datasets.items()}\n",
        "test_dfs= {key: df[df[\"month\"]==7].sample(frac=1, replace=False) for key, df in datasets.items()}\n",
        "\n",
        "label = \"fraud_bool\"\n",
        "\n",
        "categorical_features = [\n",
        "    \"payment_type\",\n",
        "    \"employment_status\",\n",
        "    \"housing_status\",\n",
        "    \"source\",\n",
        "    \"device_os\",\n",
        "]\n",
        "\n",
        "\n",
        "for name in datasets.keys():  # For each dataset in the suite\n",
        "    train = train_dfs[name]\n",
        "    val=val_dfs[name]\n",
        "    test = test_dfs[name]\n",
        "    for feat in categorical_features:\n",
        "      encoder = LabelEncoder()\n",
        "      encoder.fit(train[feat])  # Fit an encoder to the train set.\n",
        "      train[feat] = encoder.transform(train[feat])  # Transform train set.\n",
        "      val[feat] = encoder.transform(val[feat])  # Transform val set.\n",
        "      test[feat] = encoder.transform(test[feat])    # Transform test set.\n",
        "\n",
        "for dataset_name in datasets.keys():  # Run hyperparameters on all variants of datastes.\n",
        "        \n",
        "      X_train = train_dfs[dataset_name].drop(columns=[\"fraud_bool\"])\n",
        "      y_train = train_dfs[dataset_name][\"fraud_bool\"]\n",
        "      X_val = val_dfs[dataset_name].drop(columns=[\"fraud_bool\"])\n",
        "      y_val = val_dfs[dataset_name][\"fraud_bool\"]\n",
        "      X_test=test_dfs[dataset_name].drop(columns=[\"fraud_bool\"])\n",
        "      y_test = test_dfs[dataset_name][\"fraud_bool\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g27uDywwoz9j"
      },
      "outputs": [],
      "source": [
        "#Establish continuous and categorical features\n",
        "cat_cols=categorical_features\n",
        "cont_cols=train.columns.difference(cat_cols)\n",
        "cont_cols=cont_cols.difference(['fraud_bool'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zblq9zL6vWk"
      },
      "source": [
        "# Embeddings\n",
        "Defining Embeddings for Categorical Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap1yLKvMo05T",
        "outputId": "030f5d0a-101f-4e8d-8abc-4487a3f00d81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        payment_type  employment_status  housing_status  source  device_os\n",
            "765570             1                  0               1       0          2\n",
            "491426             1                  5               1       0          0\n",
            "358679             2                  3               1       0          2\n",
            "689347             0                  0               4       0          3\n",
            "115017             2                  0               0       0          0\n",
            "...              ...                ...             ...     ...        ...\n",
            "768054             3                  2               1       0          0\n",
            "389252             2                  0               4       0          2\n",
            "963569             1                  2               0       0          4\n",
            "799012             0                  0               4       0          0\n",
            "159124             0                  0               2       0          2\n",
            "\n",
            "[794989 rows x 5 columns]\n",
            "payment_type\n",
            "employment_status\n",
            "housing_status\n",
            "source\n",
            "device_os\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for name in datasets.keys():  # For each dataset in the suite\n",
        "    train = train_dfs[name]\n",
        "    val=val_dfs[name]\n",
        "    test = test_dfs[name]\n",
        "\n",
        "embedding_pipeline=importlib.reload(embedding_pipeline)\n",
        "x_train,x_test,x_val=embedding_pipeline.aggregate_low_card_BAF(X_train,X_test,X_val,cat_cols)\n",
        "dims=embedding_pipeline.get_emb_dim(x_train,'log',cat_cols)\n",
        "\n",
        "dims=torch.tensor(dims,dtype=int).to(device)\n",
        "\n",
        "import mlp\n",
        "import mlp_pipeline\n",
        "\n",
        "param_list=mlp.mlp_param_sampler(20, len(train.columns),7,device)\n",
        "\n",
        "\n",
        "x_train_cont=x_train[cont_cols]\n",
        "x_train_cat=x_train[cat_cols]\n",
        "x_test_cont=x_test[cont_cols]\n",
        "x_test_cat=x_test[cat_cols]\n",
        "x_val_cont=x_val[cont_cols]\n",
        "x_val_cat=x_val[cat_cols]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjVuBRfeq5Gi"
      },
      "outputs": [],
      "source": [
        "normalization='Zscore'\n",
        "xtrain_aux_cont=mlp_pipeline.normalization_transform(x_train_cont,normalization,cont_cols)\n",
        "xval_aux_cont=mlp_pipeline.normalization_transform(x_val_cont,normalization,cont_cols)\n",
        "\n",
        "xtrain_aux_cat=mlp_pipeline.normalization_transform(x_train_cat,'None',[])\n",
        "xval_aux_cat=mlp_pipeline.normalization_transform(x_val_cat,'None',[])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhBIYW-jpFVU"
      },
      "outputs": [],
      "source": [
        "\n",
        "normalization='Zscore'\n",
        "xtrain_aux_cont=mlp_pipeline.normalization_transform(x_train_cont,normalization,cont_cols)\n",
        "xval_aux_cont=mlp_pipeline.normalization_transform(x_val_cont,normalization,cont_cols)\n",
        "\n",
        "xtrain_aux_cat=mlp_pipeline.normalization_transform(x_train_cat,'None',[])\n",
        "xval_aux_cat=mlp_pipeline.normalization_transform(x_val_cat,'None',[])\n",
        "method='log'\n",
        "\n",
        "dims=embedding_pipeline.get_emb_dim(x_train,method,cat_cols)\n",
        "\n",
        "dims=torch.tensor(dims,dtype=int).to(device)\n",
        "\n",
        "i=0\n",
        "\n",
        "for params in param_list[i:]:\n",
        "\n",
        "        # Fit pipeline\n",
        "        print('iteration: ',i)\n",
        "        \n",
        "        model=embedding_pipeline.pipeline(device,xtrain_aux_cat,xtrain_aux_cont,xval_aux_cat,xval_aux_cont,y_train,y_val,params,'log',dims)\n",
        "\n",
        "        #Save the model\n",
        "        joblib.dump(model,'tab_norm_folder/embedding/mlp_simple{}{}{}.pkl'.format(method,normalization,i))\n",
        "\n",
        "        i=i+1\n",
        "\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ai9vexj8f-He"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "embedding_pipeline=importlib.reload(embedding_pipeline)\n",
        "\n",
        "normalization='Zscore'\n",
        "xtrain_aux_cont=mlp_pipeline.normalization_transform(x_train_cont,normalization,cont_cols)\n",
        "xval_aux_cont=mlp_pipeline.normalization_transform(x_val_cont,normalization,cont_cols)\n",
        "\n",
        "xtrain_aux_cat=mlp_pipeline.normalization_transform(x_train_cat,'None',[])\n",
        "xval_aux_cat=mlp_pipeline.normalization_transform(x_val_cat,'None',[])\n",
        "method='sqrt'\n",
        "\n",
        "dims=embedding_pipeline.get_emb_dim(x_train,method,cat_cols)\n",
        "\n",
        "dims=torch.tensor(dims,dtype=int).to(device)\n",
        "\n",
        "i=0\n",
        "\n",
        "for params in param_list[i:]:\n",
        "\n",
        "        # Fit pipeline\n",
        "        print('iteration: ',i)\n",
        "        \n",
        "        model=embedding_pipeline.pipeline(device,xtrain_aux_cat,xtrain_aux_cont,xval_aux_cat,xval_aux_cont,y_train,y_val,params,'log',dims)\n",
        "\n",
        "        #Save the model\n",
        "        joblib.dump(model,'tab_norm_folder/embedding/mlp_simple{}{}{}.pkl'.format(method,normalization,i))\n",
        "\n",
        "        i=i+1\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIISeaUQDro7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "embedding_pipeline=importlib.reload(embedding_pipeline)\n",
        "i=15\n",
        "for normalization in ['MinMax']:\n",
        "  xtrain_aux_cont=mlp_pipeline.normalization_transform(x_train_cont,normalization,cont_cols)\n",
        "  xval_aux_cont=mlp_pipeline.normalization_transform(x_val_cont,normalization,cont_cols)\n",
        "\n",
        "  xtrain_aux_cat=mlp_pipeline.normalization_transform(x_train_cat,'None',[])\n",
        "  xval_aux_cat=mlp_pipeline.normalization_transform(x_val_cat,'None',[])\n",
        "  method='sqrt'\n",
        "\n",
        "  dims=embedding_pipeline.get_emb_dim(x_train,method,cat_cols)\n",
        "\n",
        "  dims=torch.tensor(dims,dtype=int)\n",
        "\n",
        "\n",
        "  for params in param_list[i:]:\n",
        "\n",
        "        # Fit pipeline\n",
        "        print('iteration: ',i)\n",
        "        \n",
        "        model=embedding_pipeline.pipeline(device,xtrain_aux_cat,xtrain_aux_cont,xval_aux_cat,xval_aux_cont,y_train,y_val,params,'log',dims)\n",
        "\n",
        "        #Save the model\n",
        "        joblib.dump(model,'tab_norm_folder/embedding/mlp_simple{}{}{}.pkl'.format(method,normalization,i))\n",
        "\n",
        "        i=i+1\n",
        "  i=0\n",
        "  del xtrain_aux_cat\n",
        "  del xtrain_aux_cont\n",
        "  del xval_aux_cat\n",
        "  del xval_aux_cont\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85zKhcec2rzM",
        "outputId": "b4a3f328-528b-4537-b06a-957f86c5dabe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "payment_type\n",
            "employment_status\n",
            "housing_status\n",
            "source\n",
            "device_os\n",
            "iteration:  0\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  1\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  2\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  3\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  4\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  5\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  6\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  7\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  8\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  9\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  10\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  11\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  12\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  13\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  14\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  15\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  16\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  17\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  18\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  19\n",
            "----------Method: Embedding for Categorical sqrt -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "embedding_pipeline=importlib.reload(embedding_pipeline)\n",
        "mlp_params=mlp.mlp_param_sampler(20, len(train.columns),7,device)\n",
        "\n",
        "\n",
        "xtrain_aux_cat=mlp_pipeline.normalization_transform(x_train_cat,'None',[])\n",
        "xval_aux_cat=mlp_pipeline.normalization_transform(x_val_cat,'None',[])\n",
        "method='sqrt'\n",
        "\n",
        "dims=embedding_pipeline.get_emb_dim(x_train,method,cat_cols)\n",
        "\n",
        "dims=torch.tensor(dims,dtype=int).to(device)\n",
        "encoder=data.PiecewiseLinearEncoder('decision_tree',dict(n_bins=10,regression='False', tree_kwargs={'min_samples_leaf': 128}),stack=False)\n",
        "encoder.fit(torch.tensor(X_train[cont_cols.difference(['device_fraud_count'])].values),torch.tensor(y_train.values)) \n",
        "#the device count fraud feature is constant, and so cannot be fed to this encoder\n",
        "x_train_cont=encoder.transform(torch.tensor(X_train[cont_cols.difference(['device_fraud_count'])].values))\n",
        "x_val_cont=encoder.transform(torch.tensor(X_val[cont_cols.difference(['device_fraud_count'])].values))\n",
        "i=0\n",
        "del encoder\n",
        "gc.collect()\n",
        "for param_list in mlp_params[i:]:        \n",
        "\n",
        "        \n",
        "        # Fit pipeline\n",
        "        print('iteration: ',i)\n",
        "        \n",
        "        model=embedding_pipeline.pipeline(device,xtrain_aux_cat,x_train_cont,xval_aux_cat,x_val_cont,y_train,y_val,param_list,'sqrt',dims)\n",
        "\n",
        "        #Save the model\n",
        "        joblib.dump(model,'tab_norm_folder/embedding/mlp_num_enc10{}{}.pkl'.format(method,i))\n",
        "\n",
        "        i=i+1\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKhhpKoPEtlN",
        "outputId": "7ca354f9-e090-4904-d542-1ea1ad5206f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "payment_type\n",
            "employment_status\n",
            "housing_status\n",
            "source\n",
            "device_os\n",
            "iteration:  10\n",
            "----------Method: Embedding for Categorical dim=1 -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  11\n",
            "----------Method: Embedding for Categorical dim=1 -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  12\n",
            "----------Method: Embedding for Categorical dim=1 -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  13\n",
            "----------Method: Embedding for Categorical dim=1 -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  14\n",
            "----------Method: Embedding for Categorical dim=1 -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  15\n",
            "----------Method: Embedding for Categorical dim=1 -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  16\n",
            "----------Method: Embedding for Categorical dim=1 -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  17\n",
            "----------Method: Embedding for Categorical dim=1 -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  18\n",
            "----------Method: Embedding for Categorical dim=1 -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "iteration:  19\n",
            "----------Method: Embedding for Categorical dim=1 -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "#Attempting embeddings with dimension 1\n",
        "\n",
        "embedding_pipeline=importlib.reload(embedding_pipeline)\n",
        "i=10\n",
        "for normalization in ['Median']:\n",
        "  xtrain_aux_cont=mlp_pipeline.normalization_transform(x_train_cont,normalization,cont_cols)\n",
        "  xval_aux_cont=mlp_pipeline.normalization_transform(x_val_cont,normalization,cont_cols)\n",
        "\n",
        "  xtrain_aux_cat=mlp_pipeline.normalization_transform(x_train_cat,'None',[])\n",
        "  xval_aux_cat=mlp_pipeline.normalization_transform(x_val_cat,'None',[])\n",
        "\n",
        "\n",
        "  dims=embedding_pipeline.get_emb_dim(x_train,'ones',cat_cols)\n",
        "\n",
        "  dims=torch.tensor(dims,dtype=int)\n",
        "\n",
        "\n",
        "  for params in param_list[i:]:\n",
        "\n",
        "        # Fit pipeline\n",
        "        print('iteration: ',i)\n",
        "        \n",
        "        model=embedding_pipeline.pipeline(device,xtrain_aux_cat,xtrain_aux_cont,xval_aux_cat,xval_aux_cont,y_train,y_val,params,'dim=1',dims)\n",
        "\n",
        "        #Save the model\n",
        "        joblib.dump(model,'tab_norm_folder/embedding/mlp_simple{}{}{}.pkl'.format('1dimensional',normalization,i))\n",
        "\n",
        "        i=i+1\n",
        "  i=0\n",
        "  del xtrain_aux_cat\n",
        "  del xtrain_aux_cont\n",
        "  del xval_aux_cat\n",
        "  del xval_aux_cont\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAiMEH3I8pql"
      },
      "source": [
        "# Numerical Encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNrQ8mCIlD5w"
      },
      "outputs": [],
      "source": [
        "#Code for the numerical embeddings from : https://github.com/Yura52/rtdl\n",
        "import sys\n",
        "sys.path.append(\"content/gdrive/MyDrive\")\n",
        "\n",
        "from rtdl.rtdl import data as data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "JpeyKlq08WtL",
        "outputId": "230c4867-80d6-4da7-b033-468f5892b608"
      },
      "outputs": [],
      "source": [
        "link=\"tab_norm_folder/target_encoderBAF.pkl\"\n",
        "file = open(link,'rb')\n",
        "encoder = joblib.load(link)\n",
        "x_train_cat=encoder.transform(X_train)[cat_cols]\n",
        "x_val_cat=encoder.transform(X_val)[cat_cols]\n",
        "encoder=data.PiecewiseLinearEncoder('decision_tree',dict(n_bins=10,regression='False', tree_kwargs={'min_samples_leaf': 128}),stack=False)\n",
        "\n",
        "#Fitting the encoder: some binary features are also encoded, this line will raise warning due to the amount of distinct values. \n",
        "encoder.fit(torch.tensor(X_train[cont_cols.difference(['device_fraud_count'])].values),torch.tensor(y_train.values)) #the device count fraud feature is constant, and so cannot be fed to this encoder\n",
        "x_train_cont=encoder.transform(torch.tensor(X_train[cont_cols.difference(['device_fraud_count'])].values))\n",
        "x_val_cont=encoder.transform(torch.tensor(X_val[cont_cols.difference(['device_fraud_count'])].values))  \n",
        "x_train_aux=torch.cat([torch.tensor(x_train_cont),torch.tensor(x_train_cat.values)],1)\n",
        "x_val_aux=torch.cat([torch.tensor(x_val_cont),torch.tensor(x_val_cat.values)],1)\n",
        "\n",
        "joblib.dump(encoder,\"tab_norm_folder/encoders/numerical_encoder_dim10.pkl\")\n",
        "\n",
        "del encoder\n",
        "gc.collect()\n",
        "\n",
        "mlp_params=mlp.mlp_param_sampler(20, len(train.columns),7,device)\n",
        "i=15\n",
        "for param_list in mlp_params[i:]:\n",
        "    print(\" Iteration:\",i)\n",
        "\n",
        "    model=mlp_pipeline.pipeline(device,x_train_aux,x_val_aux,y_train,y_val,param_list,'None',cont_cols.difference(['device_fraud_count']))\n",
        "    joblib.dump(model,\"tab_norm_folder/numerical_embeddings/num_enc_mlp_target{}_dim.pkl\".format(i) )\n",
        "    i=i+1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "link=\"tab_norm_folder/cat_encoderBAF.pkl\"\n",
        "file = open(link,'rb')\n",
        "encoder = joblib.load(link)\n",
        "x_train_cat=encoder.transform(X_train)[cat_cols]\n",
        "x_val_cat=encoder.transform(X_val)[cat_cols]\n",
        "encoder=data.PiecewiseLinearEncoder('decision_tree',dict(n_bins=10,regression='False', tree_kwargs={'min_samples_leaf': 128}),stack=False)\n",
        "\n",
        "#Fitting the encoder: some binary features are also encoded, this line will raise warning due to the amount of distinct values. \n",
        "encoder.fit(torch.tensor(X_train[cont_cols.difference(['device_fraud_count'])].values),torch.tensor(y_train.values)) #the device count fraud feature is constant, and so cannot be fed to this encoder\n",
        "x_train_cont=encoder.transform(torch.tensor(X_train[cont_cols.difference(['device_fraud_count'])].values))\n",
        "x_val_cont=encoder.transform(torch.tensor(X_val[cont_cols.difference(['device_fraud_count'])].values))  \n",
        "x_train_aux=torch.cat([torch.tensor(x_train_cont),torch.tensor(x_train_cat.values)],1)\n",
        "x_val_aux=torch.cat([torch.tensor(x_val_cont),torch.tensor(x_val_cat.values)],1)\n",
        "\n",
        "joblib.dump(encoder,\"tab_norm_folder/encoders/numerical_encoder_dim10.pkl\")\n",
        "\n",
        "del encoder\n",
        "gc.collect()\n",
        "\n",
        "mlp_params=mlp.mlp_param_sampler(20, len(train.columns),7,device)\n",
        "i=15\n",
        "for param_list in mlp_params[i:]:\n",
        "    print(\" Iteration:\",i)\n",
        "\n",
        "    model=mlp_pipeline.pipeline(device,x_train_aux,x_val_aux,y_train,y_val,param_list,'None',cont_cols.difference(['device_fraud_count']))\n",
        "    joblib.dump(model,\"tab_norm_folder/numerical_embeddings/num_enc_mlp_cat{}_dim.pkl\".format(i) )\n",
        "    i=i+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMtpzEhy0LV3",
        "outputId": "4ffeb2cf-ca8f-4236-cd28-724b7b10538c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-c21d1f3d53f6>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_train_aux=torch.cat([torch.tensor(x_train_cont),torch.tensor(x_train_cat.values)],1)\n",
            "<ipython-input-13-c21d1f3d53f6>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_val_aux=torch.cat([torch.tensor(x_val_cont),torch.tensor(x_val_cat.values)],1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Iteration: 16\n",
            "----------Method:  None -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            " Iteration: 17\n",
            "----------Method:  None -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            " Iteration: 18\n",
            "----------Method:  None -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            " Iteration: 19\n",
            "----------Method:  None -------------\n",
            "Train size:  794989 ; Number of 0:  786838 ; Number of 1: 8151\n",
            "Val size:  108168 ; Number of 0:  106718 ; Number of 1: 1450\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "link=\"tab_norm_folder/count_encoderBAF.pkl\"\n",
        "file = open(link,'rb')\n",
        "encoder = joblib.load(link)\n",
        "x_train_cat=encoder.transform(X_train)[cat_cols]\n",
        "x_val_cat=encoder.transform(X_val)[cat_cols]\n",
        "encoder=data.PiecewiseLinearEncoder('decision_tree',dict(n_bins=10,regression='False', tree_kwargs={'min_samples_leaf': 128}),stack=False)\n",
        "\n",
        "#Fitting the encoder: some binary features are also encoded, this line will raise warning due to the amount of distinct values. \n",
        "encoder.fit(torch.tensor(X_train[cont_cols.difference(['device_fraud_count'])].values),torch.tensor(y_train.values)) #the device count fraud feature is constant, and so cannot be fed to this encoder\n",
        "x_train_cont=encoder.transform(torch.tensor(X_train[cont_cols.difference(['device_fraud_count'])].values))\n",
        "x_val_cont=encoder.transform(torch.tensor(X_val[cont_cols.difference(['device_fraud_count'])].values))  \n",
        "x_train_aux=torch.cat([torch.tensor(x_train_cont),torch.tensor(x_train_cat.values)],1)\n",
        "x_val_aux=torch.cat([torch.tensor(x_val_cont),torch.tensor(x_val_cat.values)],1)\n",
        "\n",
        "joblib.dump(encoder,\"tab_norm_folder/encoders/numerical_encoder_dim10.pkl\")\n",
        "\n",
        "del encoder\n",
        "gc.collect()\n",
        "\n",
        "mlp_params=mlp.mlp_param_sampler(20, len(train.columns),7,device)\n",
        "i=16\n",
        "for param_list in mlp_params[i:]:\n",
        "    print(\" Iteration:\",i)\n",
        "\n",
        "    model=mlp_pipeline.pipeline(device,x_train_aux,x_val_aux,y_train,y_val,param_list,'None',cont_cols.difference(['device_fraud_count']))\n",
        "    joblib.dump(model,\"/content/gdrive/MyDrive/tab_norm_folder/numerical_embeddings/num_enc_mlp_count{}_dim.pkl\".format(i) )\n",
        "    i=i+1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ3fAv6G4c6h"
      },
      "source": [
        "# TABTRANSFORMER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783,
          "referenced_widgets": [
            "fc8aee9a0a054fa692fb7dce9dc5aff7",
            "c4608d6651e94a109d1bbb679cf8cb33"
          ]
        },
        "id": "n6bpGzuC4hGe",
        "outputId": "36f41767-c7a1-4ce6-d72a-f3a746798e18"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pytorch_tabular/models/tab_transformer/config.py:219: UserWarning: Ignoring the deprecated arguments, `out_ff_layers`, `out_ff_activation`, `out_ff_dropoout`, and `out_ff_initialization` as head_config is passed.\n",
            "  warnings.warn(\n",
            "2023-02-05 21:07:33,027 - {pytorch_tabular.tabular_model:102} - INFO - Experiment Tracking is turned off\n",
            "INFO:pytorch_tabular.tabular_model:Experiment Tracking is turned off\n",
            "INFO:lightning_lite.utilities.seed:Global seed set to 42\n",
            "2023-02-05 21:07:33,132 - {pytorch_tabular.tabular_model:465} - INFO - Preparing the DataLoaders\n",
            "INFO:pytorch_tabular.tabular_model:Preparing the DataLoaders\n",
            "2023-02-05 21:07:33,272 - {pytorch_tabular.tabular_datamodule:286} - INFO - Setting up the datamodule for classification task\n",
            "INFO:pytorch_tabular.tabular_datamodule:Setting up the datamodule for classification task\n",
            "2023-02-05 21:07:36,707 - {pytorch_tabular.tabular_model:508} - INFO - Preparing the Model: TabTransformerModel\n",
            "INFO:pytorch_tabular.tabular_model:Preparing the Model: TabTransformerModel\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_tabular/models/base_model.py:126: UserWarning: Wandb is not installed. Please install wandb to log logits. You can install wandb using pip install wandb or install PyTorch Tabular using pip install pytorch-tabular[all]\n",
            "  warnings.warn(\n",
            "2023-02-05 21:07:36,772 - {pytorch_tabular.tabular_model:264} - INFO - Preparing the Trainer\n",
            "INFO:pytorch_tabular.tabular_model:Preparing the Trainer\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/setup.py:175: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
            "  rank_zero_warn(\n",
            "2023-02-05 21:07:37,006 - {pytorch_tabular.tabular_model:566} - INFO - Training Started\n",
            "INFO:pytorch_tabular.tabular_model:Training Started\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /content/saved_models exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
              "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ TabTransformerBackbone │  3.7 K │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding2dLayer       │    258 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ LinearHead             │ 44.9 K │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss       │      0 │\n",
              "└───┴──────────────────┴────────────────────────┴────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
              "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ TabTransformerBackbone │  3.7 K │\n",
              "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding2dLayer       │    258 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ LinearHead             │ 44.9 K │\n",
              "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss       │      0 │\n",
              "└───┴──────────────────┴────────────────────────┴────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 48.9 K                                                                                           \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total params</span>: 48.9 K                                                                                               \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 48.9 K                                                                                           \n",
              "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal params\u001b[0m: 48.9 K                                                                                               \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc8aee9a0a054fa692fb7dce9dc5aff7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-05 21:25:42,621 - {pytorch_tabular.tabular_model:568} - INFO - Training the model completed\n",
            "INFO:pytorch_tabular.tabular_model:Training the model completed\n",
            "2023-02-05 21:25:42,626 - {pytorch_tabular.tabular_model:1207} - INFO - Loading the best model\n",
            "INFO:pytorch_tabular.tabular_model:Loading the best model\n"
          ]
        }
      ],
      "source": [
        "import utils.tabtransformer as tabtransformer\n",
        "\n",
        "cat_cols=categorical_features\n",
        "cont_cols=['bank_branch_count_8w', 'bank_months_count', 'credit_risk_score',\n",
        "       'current_address_months_count', 'customer_age',\n",
        "       'date_of_birth_distinct_emails_4w', 'days_since_request',\n",
        "       'device_distinct_emails_8w', 'device_fraud_count', 'email_is_free',\n",
        "       'foreign_request', 'has_other_cards', 'income',\n",
        "       'intended_balcon_amount', 'keep_alive_session', 'month',\n",
        "       'name_email_similarity', 'phone_home_valid', 'phone_mobile_valid',\n",
        "       'prev_address_months_count', 'proposed_credit_limit',\n",
        "       'session_length_in_minutes', 'velocity_24h', 'velocity_4w',\n",
        "       'velocity_6h', 'zip_count_4w']\n",
        "\n",
        "params=tabtransformer.tabtransformer_param_sampler(20,7,device)\n",
        "X_train_norm=mlp_pipeline.z_score(X_train,cont_cols)\n",
        "X_val_norm=mlp_pipeline.z_score(X_val,cont_cols)\n",
        "i=18\n",
        "for param in params[i:]:\n",
        "  model=tabtransformer.transformer_pipeline(param,cat_cols,cont_cols,['fraud_bool'],X_train_norm,X_val_norm,y_train,y_val,'cpu')\n",
        "  joblib.dump(model,\"tab_norm_folder/tabtransformer/tabtransformer_zscore{}.pkl\".format(i))\n",
        "  i=i+1\n",
        "  break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ct9H92VR82E"
      },
      "outputs": [],
      "source": [
        "X_val_norm=mlp_pipeline.z_score(X_val,cont_cols)\n",
        "X_test_norm=mlp_pipeline.z_score(X_test,cont_cols)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "pYh1y9QDcAnK",
        "outputId": "49c81609-5c95-4702-f967-66309ef9f0c7"
      },
      "outputs": [],
      "source": [
        "for i in range(0,8):\n",
        "  model=CPU_Unpickler(open('tabtransformer/tabtransformer_zscore{}.pkl'.format(i),'rb')).load()\n",
        "  predict=model.predict(X_val_norm)['1_probability']\n",
        "  joblib.dump(predict,'res_prediction/yval{}.pkl'.format(i))\n",
        "  predict=model.predict(X_test_norm)['1_probability']\n",
        "  joblib.dump(predict,'res_prediction/yhat{}.pkl'.format(i))\n",
        "  break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "aAiMEH3I8pql"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c4608d6651e94a109d1bbb679cf8cb33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc8aee9a0a054fa692fb7dce9dc5aff7": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_c4608d6651e94a109d1bbb679cf8cb33",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 5/29 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">3529/3529</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:02:57 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">23.02it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.283 train_loss: 0.237    </span>\n                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">valid_loss: 2.309 valid_accuracy:</span>\n                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.495 train_accuracy: 0.88       </span>\n</pre>\n",
                  "text/plain": "Epoch 5/29 \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m3529/3529\u001b[0m \u001b[38;5;245m0:02:57 • 0:00:00\u001b[0m \u001b[38;5;249m23.02it/s\u001b[0m \u001b[37mloss: 0.283 train_loss: 0.237    \u001b[0m\n                                                                                  \u001b[37mvalid_loss: 2.309 valid_accuracy:\u001b[0m\n                                                                                  \u001b[37m0.495 train_accuracy: 0.88       \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
